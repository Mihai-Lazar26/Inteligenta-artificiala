{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e86a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "10000\n",
      "22029\n",
      "--------------\n",
      "Modelul 1\n",
      "--------------\n",
      "0.1 0.6828\n",
      "0.2 0.687\n",
      "0.3 0.6896\n",
      "0.4 0.6902\n",
      "0.5 0.6884\n",
      "0.6 0.6892\n",
      "0.7 0.6894\n",
      "0.8 0.6884\n",
      "0.9 0.6898\n",
      "0.01 0.6702\n",
      "0.02 0.6732\n",
      "0.03 0.6772\n",
      "0.04 0.6776\n",
      "0.05 0.6778\n",
      "0.06 0.6782\n",
      "0.07 0.6802\n",
      "0.08 0.68\n",
      "0.09 0.6812\n",
      "0.001 0.6586\n",
      "--------------\n",
      "0.3 0.6896\n",
      "0.31 0.6898\n",
      "0.32 0.69\n",
      "0.33 0.6904\n",
      "0.34 0.69\n",
      "0.35 0.6896\n",
      "0.36 0.6894\n",
      "0.37 0.6896\n",
      "0.38 0.6892\n",
      "0.39 0.6898\n",
      "0.4 0.6902\n",
      "0.41 0.6896\n",
      "0.42 0.69\n",
      "0.43 0.6902\n",
      "0.44 0.69\n",
      "0.45 0.6898\n",
      "0.46 0.6898\n",
      "0.47 0.6894\n",
      "0.48 0.689\n",
      "0.49 0.6886\n",
      "0.5 0.6884\n",
      "--------------\n",
      "0.33 0.6904\n",
      "[[1373  411  216]\n",
      " [ 371  967  162]\n",
      " [ 268  120 1112]]\n",
      "--------------\n",
      "Modelul 2\n",
      "--------------\n",
      "0.1 0.4014\n",
      "0.01 0.4098\n",
      "0.001 0.4642\n",
      "0.0001 0.574\n",
      "1e-05 0.536\n",
      "1e-06 0.6398\n",
      "--------------\n",
      "1e-06 0.6398\n",
      "[[1172  488  340]\n",
      " [ 333  945  222]\n",
      " [ 218  200 1082]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return (y_true == y_pred).mean()\n",
    "\n",
    "\n",
    "# Data reading\n",
    "data_train_samples = pd.read_csv('data/train_samples.txt', sep=\"\t\", header=None)\n",
    "data_train_labels = pd.read_csv('data/train_labels.txt', sep=\"\t\", header=None)\n",
    "\n",
    "data_validation_samples = pd.read_csv('data/validation_samples.txt', sep=\"\t\", header=None)\n",
    "data_validation_labels = pd.read_csv('data/validation_labels.txt', sep=\"\t\", header=None)\n",
    "\n",
    "data_test_samples = pd.read_csv('data/test_samples.txt', sep=\"\t\", header=None)\n",
    "\n",
    "train_ids = data_train_samples[0]\n",
    "train_data = data_train_samples[1]\n",
    "train_labels = data_train_labels[1]\n",
    "\n",
    "validation_ids = data_validation_samples[0]\n",
    "validation_data = data_validation_samples[1]\n",
    "validation_labels = data_validation_labels[1]\n",
    "\n",
    "test_ids = data_test_samples[0]\n",
    "test_data = data_test_samples[1]\n",
    "\n",
    "ytrain = train_labels.astype('int')\n",
    "yvalidation = validation_labels.astype('int')\n",
    "\n",
    "# Text preprocessing and scaling\n",
    "cv = CountVectorizer(encoding='str', strip_accents='unicode')\n",
    "\n",
    "xtrain = cv.fit_transform(train_data)\n",
    "xvalidation = cv.transform(validation_data)\n",
    "xtest = cv.transform(test_data)\n",
    "\n",
    "xtrain = xtrain.toarray()\n",
    "xvalidation = xvalidation.toarray()\n",
    "xtest = xtest.toarray()\n",
    "\n",
    "print(xtrain)\n",
    "print(len(xtrain))\n",
    "print(len(xtrain[0]))\n",
    "\n",
    "# Model1\n",
    "print('--------------')\n",
    "print('Modelul 1')\n",
    "\n",
    "alphaList = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.01, 0.02, 0.03,\n",
    "             0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.001]\n",
    "print('--------------')\n",
    "for alphaValue in alphaList:\n",
    "    mnb = MultinomialNB(alpha=alphaValue)\n",
    "    mnb.fit(xtrain, ytrain)\n",
    "    predicted = mnb.predict(xvalidation)\n",
    "    print(alphaValue, accuracy_score(predicted, yvalidation), sep=\" \")\n",
    "\n",
    "alphaList = [0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47,\n",
    "             0.48, 0.49, 0.5]\n",
    "print('--------------')\n",
    "for alphaValue in alphaList:\n",
    "    mnb = MultinomialNB(alpha=alphaValue)\n",
    "    mnb.fit(xtrain, ytrain)\n",
    "    predicted = mnb.predict(xvalidation)\n",
    "    print(alphaValue, accuracy_score(predicted, yvalidation), sep=\" \")\n",
    "print('--------------')\n",
    "mnb = MultinomialNB(alpha=0.33)\n",
    "mnb.fit(xtrain, ytrain)\n",
    "predicted = mnb.predict(xvalidation)\n",
    "print(0.33, accuracy_score(predicted, yvalidation), sep=\" \")\n",
    "\n",
    "cm = confusion_matrix(yvalidation, predicted)\n",
    "print(cm)\n",
    "\n",
    "predictedSubmission = mnb.predict(xtest)\n",
    "\n",
    "output = open('data/test_labels.txt', 'w')\n",
    "output.write('id,label\\n')\n",
    "for i in range(len(test_ids)):\n",
    "    output.write(str(test_ids[i]) + ',' + str(predictedSubmission[i]) + '\\n')\n",
    "output.close()\n",
    "\n",
    "print('--------------')\n",
    "print('Modelul 2')\n",
    "\n",
    "# Model2\n",
    "alphaList = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "print('--------------')\n",
    "for alphaValue in alphaList:\n",
    "    pr = Perceptron(alpha=alphaValue, penalty='l2')\n",
    "    pr.fit(xtrain, ytrain)\n",
    "    predicted = pr.predict(xvalidation)\n",
    "    print(alphaValue, accuracy_score(predicted, yvalidation), sep=\" \")\n",
    "print('--------------')\n",
    "pr = Perceptron(alpha=0.000001, penalty='l2')\n",
    "pr.fit(xtrain, ytrain)\n",
    "predicted = pr.predict(xvalidation)\n",
    "print(0.000001, accuracy_score(predicted, yvalidation), sep=\" \")\n",
    "\n",
    "cm = confusion_matrix(yvalidation, predicted)\n",
    "print(cm)\n",
    "\n",
    "predictedSubmission = pr.predict(xtest)\n",
    "output = open('data/test_labels.txt', 'w')\n",
    "output.write('id,label\\n')\n",
    "for i in range(len(test_ids)):\n",
    "    output.write(str(test_ids[i]) + ',' + str(predictedSubmission[i]) + '\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297cdb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
