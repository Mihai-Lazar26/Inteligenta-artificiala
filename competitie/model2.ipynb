{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2da97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "10000\n",
      "22029\n",
      "--------------\n",
      "0.1 0.4014\n",
      "0.01 0.4098\n",
      "0.001 0.4642\n",
      "0.0001 0.574\n",
      "1e-05 0.536\n",
      "1e-06 0.6398\n",
      "--------------\n",
      "1e-06 0.6398\n",
      "[[1172  488  340]\n",
      " [ 333  945  222]\n",
      " [ 218  200 1082]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return (y_true == y_pred).mean()\n",
    "\n",
    "# Data reading\n",
    "data_train_samples = pd.read_csv('data/train_samples.txt', sep=\"\t\", header=None)\n",
    "data_train_labels = pd.read_csv('data/train_labels.txt', sep=\"\t\", header=None)\n",
    "\n",
    "\n",
    "data_validation_samples = pd.read_csv('data/validation_samples.txt', sep=\"\t\", header=None)\n",
    "data_validation_labels = pd.read_csv('data/validation_labels.txt', sep=\"\t\", header=None)\n",
    "\n",
    "\n",
    "data_test_samples = pd.read_csv('data/test_samples.txt', sep=\"\t\", header=None)\n",
    "\n",
    "\n",
    "train_ids = data_train_samples[0]\n",
    "train_data = data_train_samples[1]\n",
    "train_labels = data_train_labels[1]\n",
    "\n",
    "validation_ids = data_validation_samples[0]\n",
    "validation_data = data_validation_samples[1]\n",
    "validation_labels = data_validation_labels[1]\n",
    "\n",
    "test_ids = data_test_samples[0]\n",
    "test_data = data_test_samples[1]\n",
    "\n",
    "ytrain = train_labels.astype('int')\n",
    "yvalidation = validation_labels.astype('int')\n",
    "\n",
    "\n",
    "# Text preprocessing and scaling\n",
    "cv = CountVectorizer(encoding = 'str', strip_accents = 'unicode')\n",
    "\n",
    "xtrain = cv.fit_transform(train_data)\n",
    "xvalidation = cv.transform(validation_data)\n",
    "xtest = cv.transform(test_data)\n",
    "\n",
    "xtrain = xtrain.toarray()\n",
    "xvalidation = xvalidation.toarray()\n",
    "xtest = xtest.toarray()\n",
    "\n",
    "print(xtrain)\n",
    "print(len(xtrain))\n",
    "print(len(xtrain[0]))\n",
    "\n",
    "\n",
    "# Model\n",
    "alphaList = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "print('--------------')\n",
    "for alphaValue in alphaList:\n",
    "    pr = Perceptron(alpha = alphaValue, penalty='l2')\n",
    "    pr.fit(xtrain, ytrain)\n",
    "    predicted = pr.predict(xvalidation)\n",
    "    print(alphaValue, accuracy_score(predicted, yvalidation), sep = \" \")\n",
    "print('--------------')\n",
    "pr = Perceptron(alpha = 0.000001, penalty='l2')\n",
    "pr.fit(xtrain, ytrain)\n",
    "predicted = pr.predict(xvalidation)\n",
    "print(0.000001, accuracy_score(predicted, yvalidation), sep = \" \")\n",
    "\n",
    "cm = confusion_matrix(yvalidation, predicted)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05429c3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
